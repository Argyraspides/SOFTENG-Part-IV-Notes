So we'll start with a brief introduction of the experimental research in HCI, followed by, uh, how to write, uh,  good research questions and hypotheses, then how to identify, uh, the variables, um, independent independent variables, generating some sample data.  And finally we will perform some, uh, statistical analysis, including T-test, uh, and uh, Anova and using Google Sheets and uh, Jasp software.  So I hope everyone have Jasp installed. Yeah.  Okay. So for the reading material, uh, the two, uh, books, I, uh, uh, got consulted.  So first was the weighing of, uh, ways of knowing HCI pages one uh,   and Experimental Research in HCI two uh , pages  to idiot.  So, uh, experimental research is, uh, crucial in HCI because, um, it helps us in, uh, systematically, uh,  investigate whether one interface is better than the other or, uh, whether one,  uh, system is better or usable, uh, have better usability than, uh, other.  So it helps us in, uh, determining that statistically and more with more better, uh, evidences.  And it also provides us, uh, clean and simple way to, uh, to make casual, uh,  causal inference is so understanding how and why things are working the way it's working.  So, uh, by carefully designing, uh, experiments, we can isolate the variables, uh, control conditions, uh,  and draw meaningful, uh, uh, inference, uh, meaningful conclusions about the user's behaviour and their preferences.  So, uh, so let's say, let's say you you developed a VR system, uh, a new VR system like Contact Lens VR.  And, uh, you want to know, um, is it better than the Apple Vision Pro?  So that's like a research objective that you want to, uh, perform.  So in HIV often want to, uh, understand, uh, which interface is better,  which interface of which interaction is better, which, uh, design is better and which process is better?  And most importantly, we also want to understand how is it better and why is it better.  AB testing how many of you have heard about AB testing used a B testing?  Do you want to tell what is a B testing program?  Huh? Mhm.  Yeah. Yeah. Yeah. Precisely, precisely. So uh, it's a control uh, it's a control procedure,  experimental procedure that very large companies uh usually follows like Google follows a B testing Amazon follows a B testing.  Uh Airbnb follows a B testing meta follows a b testing.  So in this particular uh test uh, the before UI or the existing UI is usually compared with uh the updated one.  So um, and or sometimes you can compare more versions as well and determine which is better or whatever the metrics you want to evaluate.  So usually it's before A and after B and it because this helps us in eliminating the uh,  guessing and uh, guessing work and promotes data driven, uh, decision.  So today we will use AB, uh testing framework, um, to design our experiments.  And I'll show you to you guys and you will work in pairs, uh, to develop the research question in the follow up.  So, uh. Form group of two with person sitting next to you and say hi.  Hello. Introduce themselves. Yeah. You wanna come sit a little bit closer?  Yeah. Forming a group of two is better. Three is also fine.  So it it's like a hands on activity that will keep doing.  It. Huh. Yeah. Yeah. That's okay. I mean I already have all the questions, so.  Yeah. Okay. So. Teamed up.  Okay. So, uh. Oh.  Okay. Yeah. So this is the Airbnb is, uh, from an Airbnb case study where they, uh, they ran a a b testing,  uh, for before, uh, before interface, before the whatever interface they had and after interface.  So majorly there are, uh, three changes that they want to evaluate.  So if you see I have highlighted these as well like search and filters.  So the location of search and filter has is different in A and B then the map view is different and the layout view is is different.  So this is one of the case study that they presented uh when they performed a B testing.  So we'll take this example uh, throughout this uh session.  Yeah. So uh, so let's uh, let's first let's talk about the research question in hypothesis.  Um, a good research question, uh, clearly defines, uh, what you want to investigate.  So for example, uh, does after UI lead to a faster, uh, task completion time before, uh, than before UI or, um, or, uh, it could be whether the,  uh, does after UI lead to, uh, less error rate than, uh, before UI, or whether it helps in converting more customer than, uh, before UI.  So, uh, the a good research question can be answered.  So when we write a research question, we just think from this perspective that can this question be answered?  Is this question rich research able think from a third person's perspective once you write it,  and then whether it's feasible and whether it's measurable. And based on that research question, you define your, uh, hypothesis.  Hypothesis is the statement that can be tested.  So for example, for the research question, does after UI lead to faster task completion times before then before UI,  the hypothesis would be users will complete task faster with after you than with before.  So it's just one statement which suggests what you want to, uh, say, uh, prove through this, uh, study.  Uh. So now it's your turn.  Oh, sorry. So, for the drafting research question.  So, uh, for this overall, when you start drafting the research question, think for, uh, think for a general idea and then you start.  So think, uh, um, like the overall thing.  Like what other stages, uh, or, um, like, for example, how does this design affect the user, uh, efficiency or satisfaction?  Uh, uh, or of the interface.  Um d and then for then you narrow it down, then you identify it, specific variables define the context and uh, specify the user, uh user group.  So over there then you narrow it down. You have to be, uh, very uh, you have to specify that the task completion time and novice users and,  uh, what whether it's increasing or decreasing whatever you want to.  So, so that's like narrow down. So when you write the research question, think from general then narrow it down to uh, specific one.  So it could be like what is the effect of user interface on uh elements on user behaviour.  How uh how do uh, different layouts influence, uh, user navigation, uh, on the website.  And what role does the colour play, uh, in the user interface design.  So these are like the general one. And when you talk about the specific one.  So over there you can say how does uh so for example if this is the UI, you can say like how does the change in the button, uh, colour is different.  Uh, how does it affected the conversion rate when you change the colour or searchable, uh, or when you increase the font size,  the whether it helps the elderly people to understand the, uh, the website content better.  Any questions seem silent. No.  No. Okay. So, uh, and then you draft, uh, null hypothesis.  There are mainly two types, one, uh, null hypothesis, which just says that whatever you want to say,  just reject it or say that, uh, interface A is same as interface B, there is no difference.  So that's the null hypothesis that basically which says there is no significant difference between two interfaces.  And this serves as a baseline. So ideally, um, and this is what you, what you are testing your other interface against.  So uh, you just write it like there's no, uh, significant difference in task completion time for novice users.  And uh, while using before uh, UI A versus UI B and for alternate hypotheses, it's the,  the, the thing that you want to prove where you say that there is an effect,  uh, where, uh, the, your, uh, interface, uh, is to task completion time is, uh, better than task completion time in, uh, interface B.  So this is, this actually represents, uh, researchers, uh, actually believe and, um, yeah.  So ideally, through your experiment, you would want to reject your, uh, null hypothesis where you say that if these are not same,  that means, uh, your your hypothesis, which says that, uh, the interface A is performing better than interface B is true.  So overall, the the the whole experiment, statistical test,  everything is to reject your hype null hypothesis that the overall objective of your experiment.  So now, uh, draft research questions and hypotheses.  So you and your team, so you have these two guys I gave sufficient examples.  Anyone have any question? Man nine.  In class. Any question?  No. Okay, so yeah, just my one research question for general research, question for your team.  And one narrow down question for your team and one null hypothesis for your team.  You have five minutes. Sorry, I forgot to give the timer. Yeah, it is boring and boring.  Yeah. Because we have recorded this. These rules.  So what would be your research question? General research question.  Perhaps the larger question is that things like do it yourself, the rooms be more efficient.  General question is the research question. General general research question not than what you were saying.  Yeah. Yeah I I'm not trying to a general question.  Yeah. Yeah I suppose that comes up face up after the change is more user friendly and faster to make a decision.  Okay. Those are what I guess in the question form is how fast is it take to make a decision?  That's very precise. Yes, I can do, general. I request that you would use that as the general stage.  And to me. I would, of course, meet with the South.  I think. I.  Not your place. I am finding things pretty decent here.  I bought. You can watch this video.  Can be second. This game is just one game.  I imagine that you've got that sort of tendencies.  That. Yes. Yes.  Two minutes. No. . minute left. He did not.  See a difference between designing for the.  Effective. Anyone done? Any group have completed the general research question, narrowed down research question and hypothesis.  Null hypothesis okay, so that was.  So basically. You just.  Really. I'm. [INAUDIBLE] usually play you.  That's really cool. You know.  s left, guys. Thanks.  Anyone done with this? I'm going to ask you guys, so please be ready for that.  Uh, yeah. Okay.  Time's up. So who will? Who?  Who can proudly say that they wrote the amazing general question?  Who's gonna say come on. Amazing. Yeah. Oh, yeah.  You mean the research question? Yep. Um. Because of who you are?  Yep. Should I just read that?  Or you can repeat, like I put it. There.  Okay. You need to have it recorded. So, uh, it's best that you're speaking to the mic.  Those are the people who ended up. Go on.  Yo. Testing. Testing? Yeah. Um, does after UI lead to faster us?  Uh, so user search times them before you are. Is that is that is that a valid question?  Yeah, yeah. Search time. That's a good metrics. Nice.  Anyone else? Or do I, like elect the next person?  I do want to hear. Yeah yeah yeah yeah. Uh, I liked, uh, Jordan.  Jordan got here. Yeah. What's the research question?  You just got to weed out. Yeah. You got good mates, man.  Thank you. Does after UI lead to faster task completion times than before you, uh, that's just a question on the slide, but let's just go.  Okay. What's the null hypothesis? That what? How would you say that?  If this is the research question, what would be the null hypothesis?  Well you there when I was, I threw on the bar and could see you have got good mints.  So this is a null hypothesis. Okay.  Anyone at all familiar would be like there. Would there be no effect of user search signs before and after?  Okay. Right. Yeah. Yeah. Perfect. So that's that's that's why it's very easy to sort of write a initial null hypothesis.  Anyone else? Anyone else wrote anything else other than the task?  Uh, search completion time or search time?  Yeah. No. Okay?  Yeah. Give me a second.  I'll be there soon. Sorry.  Sorry. Pisces. Uh, yeah. Uh, our hypothesis is that the new design will shorten the time user from searching the hotel to, uh, order it.  Yep. So from searching to hotel to order. So that's like conversion.  So basically having a big site say, what was the big image size or.  Yeah. So what was the big image size or UI?  A will increase the, um, the conversion rate, increase the, uh, um, the number of the order.  Okay. Number of orders. Okay. Yeah. So basically, the null hypothesis would be that there is no change in, uh, number of orders.  Okay. Thank you. Uh, nice.  So. So one sample, uh, for those who, uh, who couldn't write, uh, complete the research question.  I just wrote one. So, uh, sample research question, uh, could be like, what is the impact of a grid layout versus, uh,  list layout on the search efficiency of users in the booking app when searching for accommodations?  So this is like one sample research question. And then the null hypothesis would be there is no significant difference in search efficiency, uh,  between users when the grid and uh, list layouts, uh, using the P in uh, list layouts when searching for accommodations at Airbnb.  And then second, I just changed the metrics.  So as you see, uh, difference in search efficiency versus, uh, and the second null hypothesis is the user satisfaction.  So for my research. So I had two research questions.  And then I made two uh hypothesis okay.  Any questions. So for anyone didn't understand.  Yes. No. Come on. You all have voices?  Yes. No. Okay. Nodding.  Looks cool. So now, uh, we come to variables.  Do you guys know about variables? Have you taken the HCI class or heard?  Heard about independent and dependent variables anywhere else?  Yeah. Okay. So, yeah, independent variables are the, uh, the things that we manipulate.  So for example, in my, uh, I mean, I'll ask you, for example.  And then in the dependent variable, uh, is something that we measure.  So if the two for my two null hypothesis, what do you think would be my independent variable.  And what would be my dependent variable. Any guesses? Yeah.  Layout is what anybody named.  Variable. Oh, I wrote it. Nice and dependent variable.  Huh. Search efficiency. Nice. And and user satisfaction.  From. How do you measure service efficiency? Uh huh.  So. Yeah. So we measure the search efficiency by measuring the task completion time.  How much time they took. So that's those are like the behavioural measures that we have.  So there are three types of measures one,  subjective measures where you have questionnaires for example system usability uh test where you can just ask questionnaires or you know,  you might have seen in the like after you completed shopping, you ask, you see like how was your experience in some smiley faces?  So that's a subjective measure, a way of collecting the data.  Then second, uh, is your behavioural. So task performance time, uh, task completion time, error rate.  How much how many errors you made while completing how many?  Uh, yeah. And then third, it comes as the physiological, uh, data, which is like your heart rate and other.  So which is not in this particular session at the moment.  Okay. So, uh, search efficiency,  user satisfaction are the independent variables and sorry dependent variable man and uh grid layout are the independent variable.  Search efficiency and user satisfaction are the dependent variables. So uh, experimental design.  So when you have your, uh, variables then next step comes when you have to decide whether your experiment should be,  uh, within subject or between subject study or, uh, mixed, uh, mixed vectorial, uh, study.  So within subject is uh, is the experiment then.  Okay. I'll ask you guys what is within subject. For his participation.  Mhm. So how would it happen in the AB testing that we are performing.  What will. So if there are two you is what will one participant has to like.  How would the within subject uh work in the abbey testing scenario.  Would that be? Both. And. Yeah.  So yeah basically one. Yeah. One participant has to experience both A and B and then evaluate.  But so so that's within. But then uh over there if one participant is performing using all the interfaces then there is a potential of a  carry for forward effect where let's say if you tried interface one and after five minutes you try interface two.  So you still have some, you know, your, uh,  intuition or your learnings from interface B that you would try to implement interface uh B so that will impact your experiment design.  So if you want data to be completely separated or from different participant group,  then you run a between subject where one participant group uh performs only  or uses only interface A and one participant group uh uses only interface B.  So in that there is no uh carry forward forward effect.  But then um for within a for between subject, you need more participants to, to increase the effect size.  Yeah. And this is entangle. Okay.  It takes a okay. Don't want to make bad jokes. Okay.  Any question? Yes. I was wondering what would be the best.  What would be the. I could really hit you with these off the concepts of any of these?  Yeah. So far ab testing mostly it's between subject study because it's like it's at a very huge scale because if let's say Google or Amazon is uh,  or Airbnb is doing their AB testing, so they would have like thousands of uh, user data.  So they will give one interface which is the existing  to  sample, which is like  or   people.  And then you interface to the other one so they, the user don't get to use that same, uh, same interface.  But then let's say if you are running, uh, study where you are comparing your VR contact lenses.  So in that case, because, um, you would prefer to have the same participant going through both the, uh,  the like the experiences and rated because then they,  they have a baseline because it's a novel interaction, novel design and also uh, for within subject.  Uh, the the drawback is, uh, I mean, the good thing is you, you do not need those many participants,  uh, for that, uh, for the study and then less variability.  Yeah. Any other question? No.  Okay. Okay.  So yeah, in this lecture we will be, uh, focusing on the, um, on the between subject, uh, design.  So for the data collection, for my research questions, which were around the search efficiency,  uh, I wanted to or, and user satisfaction for my null hypothesis.  I wanted to collect data, so I had task completion time in minutes.  So which is one of the metrics I am collecting through the experiment, uh, which takes, um,  so the time it takes for the user to find and book the accommodation and then the user satisfaction,  which is like a satisfaction score at the end, I asked them to rate between  to , where one is not satisfactory at all.  And five, uh, means very satisfactory based on user feedback. So these are the two data that, uh, I collected.  Now, uh, since we don't have time to run the experiment.  So I thought, let's use ChatGPT to generate some data.  Yeah. Okay. So, uh, I it's for the groups, whatever groups.  So you have your hypothesis research question written with you. So now change the parameters.  So this is the prompt exact prompt that you if you give you will get the table of the data that we want to generate.  And this QR code is the whole text file or like the text.  So you can can use it so you have time. Please generate your data for your metrics.  So for example, uh, if you read this, uh, please generate some sample data for a user study comparing this,  this, uh, the data should include task completion time.  So task completion time is my, uh, dependent variable that I want to measure.  So this is the data it will generate. And, uh, so right now it's  participants for, uh, grid layout and  for, uh, list layout.  So grid and list are my independent variable. So change it according to yours.  Yeah. And at this moment, I asked the ChatGPT to generate the data, which sort of is inclined to or show like a clear, significant results.  So for now you, uh,  generate using this and then later you generate using without the objective and see what's the difference when we run the statistical test in later.  You have five minutes time. If you have any question, please feel free to ask.  Yes. Everything's great at scale.  I can put commercial. But because that we're doing research that one.  Because if we're sorry, if we're doing research because we're the company side.  Mhm. And so just doing our best that like we are going to uh I realise it's low stakes.  Yeah I mean I they have the terms and conditions where they say they'll use your data for experimental purposes.  So by agreeing to that you would by default agree to that.  And then cookies and everything are there. But then yeah I think they don't change like for every AB testing.  So this current example is for a major revamp.  But usually the interface change would be just about if the, uh, let's say if the data analyst or data scientist found out that, you know,  there is no, uh, the conversion rate is not because of the font size or the contrast between the actionable button call to action button.  So if there is no, then they'll change to a different just call to action button and run the test and they'll make the change.  So yeah. I didn't try it with GPT four though.  I tried with ChatGPT for oh, so.  Yeah, try if you can generate your own data. This.  Half time up. . minutes.  Please generate. Generate the data. Paste it in a Google sheet.  Yeah. Paste the data in Google Sheet AI. Next slide would be about how to how the data looks like.  But. Oh.  It's important. You.  Pretty good for you. s left.  Time's up. Of course, everyone got their Google sheet.  Yes. No. Yes. No. Yes.  Okay. Good. Cool.  So this is the sample data that I have collected.  So anyone who couldn't get their Google sheet done or done, you can, uh, copy the data from this, like Google Sheet.  Uh, so this is how your current data should look like, where you have your participant ID.  So when you run the experiment, usually it will be like a random, uh, random sort of sequence.  So if you see participant one grid participant two list.  Participant three grid.  So this is how you will be logging the data when you, uh, collect the like when you get the questionnaire results or whatever task completion.  And then after that you will have to clean the data for your software or whatever software you are using.  You might have to clean the data, or sometimes it just works directly, uh, using this particular data format.  So that's that's data cleaning and all that. So that you that is not part of this, uh, lecture at the moment.  So. Now, uh, should we give, like, a break?  Yeah, maybe like a five minute break. Cool.  So, yeah, maybe once you, uh, you have downloaded, uh, the data, we can take five minute break and then we can meet afterwards.  It. And while I know that no one wants to go to toilet.  I want to go quietly. This like.  This a great a business? I was just looking at you.  I mean, you look over  years old.  You know. Revelation.  Turbo. But.  And then based on. Was not accompanied by.  Like. And. If you're not happy with your weight loss, I wasn't here.  When you were. So you come up with something?  No problem. On his own.  If you take the. Things.  That affect. Yeah. Graduating college.  Is still to be eligible, but more likely to.  I think I did this for the fourth time.  Is the first step. I yeah that's right.  That's my business or pleasure because I think this this one, this thing is like like you know, hey you know, this minimum I wouldn't say too.  I think they just gave us this whole. This is the first of its kind.  This is. Please remember this.  Uh. Yeah.  It's just like, uh. So. Sorry.  Earlier the file, I don't know, there was some settings.  Uh, so now you can copy, change or download the file.  Uh, cool. Yeah.  So this is the data file that we have now.  And I pasted, uh, the, uh, the chat prompt over here.  You could. Uh.  Come here. This is.  Great. So now when you have the data.  Are you guys settled then? Yeah. Okay, so now you have the data.  The next question comes. What kind of test? Uh, statistical test you would want to run.  Uh, and which is a very, uh, big, uh, question, like when you are designing a study and you are not aware of it.  So for that, uh, this table summarises, um, like the test, for example, if the experiment design is between group,  then and the independent variable is one and the conditions are two,  then the type of test would be independent sample uh t test if you have uh one variable.  So for AB testing because it's one independent variable and two conditions A and B.  So you just go with like independent sample uh t test.  But if let's say if you have more than one interfaces uh to evaluate but you have only you have varying only one.  So let's say if you want to evaluate ListView versus Gridview versus mixed view where you are mixing less than, uh, great combine.  So you have three groups performing the activity. So you will have three conditions.  So in that case you would have to use the one way Anova.  Um and if you have more than one independent variable where you are also changing, let's say uh one the layout.  Second, maybe the device like desktop versus mobile. So that's where you have the second independent variable.  So in that case uh uh and yeah so two by two.  But then the Anova would be factorial uh Anova.  And if you have a within subject study. So in let's say if in your research project you have two independent variables  and you want each of each participant to go through all the four conditions.  Uh, so in that case, uh, it's a variance object.  And if you have only, uh, one variable, then it's repeated measure Anova.  Uh, and if you have more than two then it's repeated measure Anova.  But then I think the settings uh could be uh different for that.  So I will show that later. Any question.  No. Yes. Okay. So, yeah.  This image is from the book Experimental Research in HCI.  Uh, chapter . and page . So this is from one of your reading materials.  I have a question. Why do we need significant testing?  Oh, that's a very good question. I was hoping to explain it during the interpretation.  Okay. Huh? Yeah. That's why later. Yeah. Significant.  So we need to, uh. Okay. Yeah, yeah.  I will come to that point when we are interpreting the results. I think.  Sorry. Anyone have any question for Wilkins on the Anova?  Yeah. So if you come I will discuss. So this is one of the type of test is called analysis of variance.  So this is one of the test you run. Um yeah.  When you have um, more than three conditions.  Uh, yeah. So I will explain that, uh, in the upcoming slides.  Yeah. So I will explain t test and Anova both later.  Yeah. Okay. So t-test.  It's it's. Yeah, it's a basic, uh, t test is also called student t test.  Uh, and when you use the independent data and you compare the averages or means of, uh, two separate groups, uh, that are connected.  So like basically independent, uh, between subject study and, uh, two variables, uh, two conditions.  So two, uh, two groups to compare.  So, um, when you run the t test, then you get a T value which indicates whether the difference between the interface,  the average of two groups is, uh, significant or not.  And the higher T value, uh, more likely means to, uh, to, uh, more more likely, uh, means that means that two means are different.  And the data should be. So one of the assumption for this, uh, to run this test is the data should be normally distributed.  So when you ask okay, do you have any question about normally distributed.  Do you know about normally distributed data. Okay.  So yeah that was part of the course. But then I can explain.  So um, when you collect a data and when you plot it so or sort the data, then you make like a uh Gaussian bell curve.  So the data should actually make like a Gaussian bell curve.  I think I have a slide later for.  Yeah. Yeah, I have a slide. I will show you how the Gaussian bell curve look like.  But then the data should be follow, should follow that distribution pattern.  When you analyse uh run the t test uh on that. So there are two types of uh t tests.  One data is for independent data and another one for, uh, t-test for uh, for the paired data or so in simple terms,  independent data for between subject and uh, t test for paired data is for the within subject study when one participant is experiencing both.  So this is the formula uh t is equal to.  So x one is your sample mean. And uh minus the sample mean of x two divided by the uh variance of uh first.  So the ratio of variance and uh some total number of participants at that and square root.  So it's a formula for t test. And we will we will perform this in Google Sheet.  Yeah. So now the Hands-On activity. Now we have the data. Let us try to use Google Sheets to interpret uh I mean to analyse the data.  Now you guys ready? You have your Google sheet. No.  Okay. Okay, so.  I have already populated so that you can just follow the formula.  So, uh, you see, I sorted this, uh, for Google Sheet.  We need to have two tables of, uh, two columns for individual, uh, uh, variables.  So I just sorted the, uh, the whole, uh, sheet based on the layout, then had these two grid and, uh, layer list column with all the data over here.  Are you guys following the step or should I just explain? How did you how did you make the grid layout?  Um, like, how did you, um. So you just do that?  I mean, there's no shortcut, but you just take I mean, just take these three go to data short range,  then you just tell it data has a header layout and Z, and it just sorts all the data for you.  So I just did this to bring to make all the data look like this.  Then I just copy pasted this grid data.  It is grid data over here and list over here.  So once you are done till here let me know. Then I will start explaining the rest of the formula and other things.  And in this sheet I have put all the resources that you would need to understand students data.  So there is this good video as well. So if yeah, if you are confused about anything, whatever I said you can watch this video later.  So we are right now we are using Google Sheet like a difficult method.  After this I will show you one click or two click or four five click solution as well.  So once you are done till here let me know please. If you guys need help that you discuss the help you all.  So we just show that shortcut. Yeah.  So so select data then go to data option, then short range then advanced range sorting options.  When you click on it you see this list. Then you select on data has header row because your data has.  So over here you see participant ID you select layout. You want to sort the data based on layout and then just sort of things you.  Yeah. Yeah.  I mean, uh, you guys, if I mean, if you are good in Python, you can use that also.  It's just it's just one way. It's just.  To. We're not exactly.  Yeah. Done.  You know, it's. Okay. If you are done, raise your hand, please.  I mean, till here. Till the. When you make the list. A column of this.  When if you're trying to implement a formula by yourself, that's amazing.  How many of you have used a Google Sheet for data analysis, or any kind of Google Sheet or Excel for any kind of analysis like data analysis?  Huh? Yes. You have used SPSS.  Okay. So that's like one of the softwares. But we won't be using SPSS today.  We'll use it like a free version of it Jasp. So yeah yeah but not Excel.  Yeah. Google Sheet and Excel are amazing in data analysis. You actually don't need a lot of other tools for that.  Like it can it's very powerful if you don't know how to use it. Cool.  Okay, one more minute. So whoever is done with the listing.  Uh, great. Analyst column over here make three, uh, three rows of, uh, one for, uh, mean, one for standard deviation and one for variance.  And I think you can make one for number.  Participate. Spinning mystic.  Is. Okay, so, uh, do you know how to calculate mean in Excel or Google Sheet?  Please raise your hand if you know how to use. Yeah okay.  So the formula for to calculate mean is straightforward.  Use put is equal to average.  And then uh. So this is is equal to average.  It will suggest you select and then just select the data range from here to here.  And then this will give you the mean of this data.  And then you do the same for this.  And Google Sheet will all automatically suggest you.  So this is how you got the mean mean value.  Any question. So next after that you similarly get the standard deviation for this data.  The formula is stdev stdev.  So uh and then similarly you just put STD.  Uh and it will select the data.  And then similarly and then select and then variances.  Also there is a function for that. So variance is the square of the standard deviation like yeah that's the variance.  So the function is var. So when you select var it will do the variance as well.  So these three these three. Oh.  Yeah. Okay. Okay.  Cool. What is just most of all, what goes on behind the scenes?  Yeah. He looks better.  Yeah. Okay. Okay.  So, uh. Once.  Once you are done with, uh. Are you done with the mean standard deviation and variance as well, or.  Yeah. Okay. Say yes or no, please.  And this is for the participant number. Like what is the total number of participants.  So that is just count. So you select count and then.  Uh, [INAUDIBLE]. Okay. Sorry. Yeah.  Oh, okay. So you see  participants.  Okay, so now, uh, when we have the mean, we have standard deviation, we have variance,  and we have the participant number like the total number of participants.  So then we look at, uh, this formula. So over here it says d is equal to x one minus x two.  Like mean subtract the mean.  So I use the formula over here.  So numerator is uh. Yeah.  Sorry. Numerator is the absolute value of, uh, min of one.  Minus min of two. You guys know what it's numerator numerator of.  So the top part XX minus x two is the absolute of uh mean subtraction of the means the group mean.  So group mean of one subtracted with the mean of second and taken absolute value of that.  And then the second is the function uh is the square root of.  So over here this is your x one square is the variance S square is your second groups variance.  And one is the number of participants for group one number of partitions or the sample size for part uh, group one sample size for group two.  So the formula is square root of variance one divided by sample size one plus variance two plus uh divided by the number of participants two.  So this is your denominator. And then when you take a ratio of this the value would be . something.  An equation and this variance divided by the, uh, in the denominator.  Yes. No. No. Sorry. Variance divided by the number of per sample size.  Yeah. So SS is like square of your standard deviation.  So that's the variance. So that's why I just simplified it. So if you have I mean if you take square of this this is also same.  You can call it like standard deviation square. But I just call it variance.  Divide by n one to simplify.  And if. Yeah, I mean this video if you if you are keen to know more on in-depth, just have a look at this video.  Okay, so now let's say a few. Are you guys falling with me or.  Yeah. Or you're waiting. You're okay with taking that?  I mean, yeah, take the data or whatever the values you want or the formula from the Excel Google Sheet that I've shared.  But then. Yeah. So this T value is the ratio of, uh, yours absolute difference in the mean value divided by the uh,  that and uh, the ratio of square square root of variance ratio, variance in sample size.  It's difficult to explain. So, uh, is it clear?  So once you have the t t value. So the your test is not completed yet.  So right now with just this value, you can't say whether you are accepting or rejecting your null hypothesis.  Right. So let's say if you got this value then after that you have to look at the uh t table.  So this is the T table that I have put in. So this t table is based on the distribution or like confidence level.  So confidence level is like the area in that uh Gaussian bell curve that I showed.  So in that how how confident are you that the values that will lie between that % if let us say okay, okay.  Let me let me try to rephrase it again. Let's say if you tried grid, uh, grid Layout one, right.  And you have some data and then you say you have a, uh, list layout, do you have a data?  And you say that the Gaussian curve of that, like the overlap, the curve overlap.  It's sort of like the confidence level of you, a participant performing, uh, the same or getting the same results when performing the other interface.  Uh, is the value, uh, false between the % of the area of that Gaussian bell curve.  So, I mean, sorry. Yeah, it's there in the slide I in the interpretation slides.  So. Yeah.  When will. Yeah. When will interpret I will explain. It is just while when I can essentially just copy and paste it over here as well.  I don't work like this. Sorry. Yeah, I'll do it. But, yeah, this is the bell curve.  I'll explain it later, but yeah.  Confidence level V in the in HCI studies usually we take % confidence level where we say that participants who are getting the same,  same uh, let's say time, completion time, uh, are sort of different.  The . Okay. Out of ten times,  times a person, uh, takes, uh, the grid gridview and, uh, % the list view % of the time the data is not same.  So it's like it's not happening by chance. It's happening because of the variable that you're manipulating.  Something like that. I mean, I'm sure it's not clear at this time.  Right. So event. So sorry. That's what you get.  So yeah this t test. So you got this T value.  You got this t value. Now you have a t table. And you look at this % confidence.  And over here you see something called DF.  So DF is your uh is your sum of participants, uh, sum of both the groups, uh, sample size subtracted by two.  So your for now for this particular, uh, study where we have  participants in total, like  for group  for group B, so we got DfES .  So next you have to see your DF lies between  and  over here.  And you have to see the value that you know. So . and two.  So our value is eight. And it's definitely more than the critical value.  So this value is called the critical value not getting okay.  So for the HCI study, we'll just consider this % confidence level row column.  Okay. And based on your study. So if you let's say if you have uh,  participants in your group A and  in Group B, so in total your participants.  So your DF degree of freedom. So DF is the degree of freedom would be the group uh, size.  Uh, once uh, sample size plus group size two subtracted by two.  So that's how you get the DF. Now you have to check in your % result, uh, column and the DF.  What is the critical value for this particular, uh, scenario?  So, for example, in an ideal world scenario, uh, if your, uh, t test should give the value of around . to  or between around two,  if the value is two or above two, that means it's significant.  So that means you can reject the null hypothesis. Okay.  No. Doubtful.  Is it usually that we get such a high that.  No. No. It's because. Yeah, exactly.  So that's why I was asking you. Try removing the objective and change the range.  Because right now the for the list view and the grid view, I deliberately change the range.  So when we run the actual studies, the data the mean is not that different to you.  So this is just to show how you can get the statistically significant results.  So try this by yourself. Generate another data which is sort of like overlapping and see how the t value is different.  So this is like one of the diff. I mean this is the manual way of doing the t test.  Right. So everyone understood how we got the critical value.  Yes. No. So for your study let's say if you have around  per group, let's say  participants per group.  So then your DF would be around nine nine like five nine .  Right. So then you have to look at your degree of freedom over here whatever the range.  And %. So this value would be a critical value.  So ideally your t value should be more than. This value does not matter how how big or how less.  As long as it's higher than that. That means basically the higher the better.  But then at least your data is, uh, significantly different and your null hypothesis is rejected.  So another way of doing this in Google Sheet is this function which they provide.  It's called t dot t test. So. Yeah.  So over here you just type t dot test and then you select.  One data one. Then you select data two, then you second, then it has four.  For argument's sake, one data one, data two, then second is about the tail.  So by default we go with the two tailed test.  So this is called two tail. I will explain the tail after.  Then I will show the graph. So then you put two for two tail and then second type.  So one if that's if the t-test is a paired t test then one and two if the t test is the independent t test.  So for in our case this is independent. So we'll put two and then.  So right now you see zero because the data this the value is less than ..  So that's why it's uh you can see it as zero. It's highly significant.  When you run on a not insignificant data then you will see a different value over here.  So this is the t p value that you get. So p value is the uh uh yeah I will explain p value in the next slide when we are interpreting the data.  Yeah okay. So yeah this is how we analyse the data.  Uh t test uh, in um in, in a Google sheet.  Now you guys have jasp install.  Yeah. So for jasp. We'll just copy.  The sample file like this. This is Jess.  You have Jess open. Yeah.  No. Okay. So over here, the when you start the in the software it looks like this.  Then you select on new data and then you select over here.  And we have already copied the data. So I just paste it. So you see one column is my layout.  So this is my conditions or the independent variable.  And this is my dependent variable which is time completion time in minutes.  So you just have to copy. Copy the sample data not in the sorted form but in the actual form.  I mean I, I don't think it will matter, but yeah. So once it's done, let me know when you have pasted the data.  Whoever is trying hands on. Again, if you do any help and you're not sure if you edit the data correctly, that users are allowed to help you.  And he's also good on you then the box about.  Yeah. So I think that for some of you still confused. Oh. I think they need to see it in.  Of course. Yeah. Yeah, that's what it.  So as it him. And.  Even though they haven't get what it's been.  I think at that point is the interpretation slide.  What do you need to do? Do you think I should just want to show them the text and then the interpretation.  Would it like this is almost impossible. Okay, let's move on.  Okay. So you think I'm. Done?  Yes. No. Thank you.  Guys. Yes. No. Yes. Yes.  Okay. So when we pasted the data over here.  Now next we have to go to analysis. And over here you see t-test.  Straightforward. And over here you see independent samples t test.  So this is what we want to use. So over here you will see this uh interface where you will see this layout and uh task completion variable.  So and over here you have dependent variables and grouping variables.  So in this which one is uh grouping variable and which one is the dependent variable.  Which one is grouping? Which one is dependent? Can you see?  No. Have you? Uh. I don't know how to zoom in.  Is there, like an assistant make zoom thing? Windows option commands the trying to use plus common stock.  It doesn't work. You know.  Is that okay. This is layout and this is task completion time.  Which one is grouping variable. Which one is dependent variable with the office who layout is drooping okay.  And your task completion time is dependent. So when you see over here this calculated r t value to be -. and df uh  and p value ..  Well, that's where I want you to focus.  On this morning for one point. It got to be wrong.  You know it's quite solution just so that it's a bit of physical significance of it's not just number.  Yeah. Some something to do. Uh, some idea of comments and comments from my comment.  And so the question is look like it gives us a good read.  But we can go to System preferences or System Settings displayed and the resolution system settings you mess with uh portion.  It would just follow what it was. But yeah, there is a risk with in regards to the recordings.  Yeah, yeah. Uh, yeah. So let's say if I'm making a low resolution of people to make it better.  Yeah, I'm like that. Thank you.  Is it better now? She found excuses. I think she probably.  So if you could just move into a value proposition exam.  Yeah, that's what I'm also looking at. So that's it.  I didn't yeah it was it's. It is.  Shipping the. Of those conventions of which.  Yeah, I know this formula.  So how does he do that? Yeah. So it doesn't. He did not make it all the way.  Thank. Yes.  Yes. Yes. The denominators of hospitalisations.  Flexibility. Yes. Correct. No. Otherwise, no.  Oh. Is using the same formula for the other side, and it should be the same formula.  Well, if you run the which is the one for the t test here, I just saw zero zero.  Yeah, that's why it's here. That a lot of the British ones called.  Lawrence King for over a year. But the funny thing is that that hasn't been proven.  We didn't know. Yes.  Yes. Absolutely. Yes.  Oh, look at this house. Yeah. Oh, so just didn't get into the last six of us.  So maybe we can just. Yeah, it's a negative here, but.  Yeah, I mean, this is about the tail, right? Smart enough to say I love this detective.  I mean, the formula for the t test requires it to be an absolute someone once you get it the way, the absolute opposite.  So independent sample show you do the same. But you ran this before.  You ran before? Yes. So I mean, I ran for.  My then it. But now we're not going through the exact same data because I changed this morning.  Maybe that's the lesson for the students that try this hopefully for you.  I mean, this is also a thing that if you run this on SPSS the value would be different.  The value will be different. But some other things as important differences.  So everything yeah I like to look at this.  Would you like. To go back with those things.  Yeah. In order for us to select.  I don't know that I can get out of this.  Yeah. So every once in a.  On. But you.  In. I don't know.  It's fine. Put the data. Okay. I'm a little concerned.  Yeah. So, uh. I mean, I'm not sure why the data t value is different.  Uh. Over here.  Yeah. Yeah.  So the T over here, I am not sure why the value is different over here and, uh, software.  But then this is also a thing that the t this t value doesn't matter that much as long as your p value is significant.  You know, uh, but if you try the same thing in Python just using that formula, the, uh, like the function, uh, the value would be different as well.  So there is no, uh, there's no specific sort of, uh, way to say that this software.  So that's why SPSS is one of the academic grade that we usually use, which is just you select something and then done.  This is the first time I'm also trying s uh, just so I don't know about the accuracy level,  but then it will tell you whether the data is, uh, significant or not, whether you have to reject the null hypothesis or not.  So you can trust it in, uh, at least that way. So let's say now, uh, yeah.  Moving on. So let's say if you got this, uh, value over here, uh, let me remove whatever.  So yeah, you got a T value, you got the DF and you got a p value.  So now what? How to interpret, uh, interpret this data and how to report this data.  That's that's a question. So. Coming through here.  It means that you think that the darkest hour is always.  You say. Uh, and it's been a whirlwind.  Okay, cool. So when interpreting the result, you have to, uh, consider that, uh, the higher the T value,  the greater likelihood of the significant difference between the mean.  So when I was talking about the normal distribution, this is how the, uh, Gaussian bell curve, uh, look like.  So ideally, before running a t test, you would also run a test of normality to check whether the data is normal or not,  whether the data is following this Gaussian bell curve or not.  So, uh, if over here, you see, like if there is a mean centred mean, then you see the standard deviation, uh, over here.  So most of the, uh can you see my.  Yeah. So over here, this is the this is the data.  Uh, this green and yellow is the data, which, uh, falls under the, uh, the % confidence interval.  So if, if your data the both the means.  If so, let's say this is the mean of one like the distribution of one and second.  If both are overlapping, then you have to see if your data is, uh,  your t value of whatever the t test value is falling between these, uh, . on this side, uh, . on this side as an outlier.  So most of your data should, uh, should, uh, should be, uh, falling between, uh, the mean and the first standard deviation.  And this is your second standard deviation, which is your variance.  So if your, uh, so when we try to prove our null hypothesis or reject the null hypothesis,  uh, your, uh, so I also mentioned about two tail, one tail and two tail.  So one tail is when we talk about a specific direction, like when we say that great UI,  uh, will lead to a faster, uh, uh, faster, uh, completion rate.  Uh, then the um, like then your, uh, current, uh, the existing one.  So that's where when you are, uh, saying that, uh,  or when when you say that the person who use the great UI will perform better than someone who have not used the the great UI.  So this is where you are sort of directing, uh, a particular, uh, a particular hypothesis where you, you are telling that this would happen.  But then when you are designing a, uh, experiment, you have to keep both the possibilities have, uh, possible, uh,  both the possibilities in consideration that your data could, uh,  your t test could result in your grid layout to be better or your, uh, list layout to be better.  So that is why we usually go with two tailed test. So when we say two tailed, you look at .% of the side and . percent on, uh, this side.  So over here, over here overall it will be like point zero.  Point five. So %. Uh, %.  So that's why we just keep the interval confidence level, uh, in HCI studies as %.  So like other things are just outlier. And when you report, uh, when you report the data,  so you just write an independent sample data such as that there is a significant difference in the task  completion time between the groups who use the grid layout and the groups who use the list layout,  and you just report the values. So this is like an academic way of reporting the data.  Okay. So next comes, uh, we come to the analysis of variance or Anova.  So, uh, with two conditions, you can compare the mean and say like okay, this may this condition is better or this mean is better.  That mean is better.  But uh, with when you have more conditions then it, uh, when you have more than two conditions, then other variable also comes into place,  whether there is uh, effect of uh each condition in among themselves as well, like uh for, for example list versus grade versus mixed.  So in that you also have to see whether there is some interaction effect between grade and mixed and uh grade and uh list and grade and all those.  So there is some between uh within group. Uh uh uh error also comes into factor.  So Anova is the variance comparison.  Not just the um not just the main comparison. And uh, the final result comes as a F score.  So they usually follow this formula F is equal to uh.  O f is equal to MSB divided by m w.  So MSB is the mean square between uh groups and MSB is mean square within groups.  So over here you see the formulas, which is very complicated.  Uh, yeah. So mean square between group and mean square within groups.  I think, uh, in the Excel in the Google sheet, there should be, uh, like some activity over there as well.  Yeah. Uh, yeah.  So there are two, four, mainly four types of Anova one way Anova.  Uh, which where you have uh, one which is between group study and you have, uh, which uh,  investigate only one independent variable and have three or more, uh, conditions.  And the data is normally distributed. So that's also an assumption for that.  So let's say if you are just doing the list versus grade versus mixed.  So you have only one independent variable. So just use one way Anova for that.  But then if you have more than two variables so grid versus uh list and mobile versus desktop.  So in that case you go with factorial Anova. So uh for one way Anova the question could be like what is the impact of different layout design.  And on the task completion time of the users.  And looking at factorial Anova, it would be how do you layout, design and device type interact uh, to affect user satisfaction and booking app.  Then third one is uh repeated measure Anova.  So which is uh mainly used for the within group conditions.  So if you are running a user study where you have uh you are using within group, uh, uh,  experimental method, then uh, and you have more than two variables, then you uh, use repeated measure also.  So yeah, one way repeated measure Anova when you have only one independent variable and two way when you have more than  or  or more than that.  So for one way repeated measure Anova, the example research question could be like how does user satisfaction change over time?  So in one week, second week and one month.  So three times you ask the questionnaire and get the data from user using the grid layout in the booking app.  And then the two way repeated measure Anova. Uh, you ask how to layout design, grid versus list and the session time morning versus evening impact uh,  user satisfaction over multiple sessions in the booking app. Okay, so hands on, I think, uh, we have uh, any question from Anova?  I mean, I know there will be a question about the formula, but other than that.  No. Okay. So in Anova.  I have generated a sample, uh, data over here as well.  So you see, uh, grid list mix. And this is the prompt.  Yeah. So now next activity for you would be to see what you do.  Actually, uh, formula wise it would be complicated D.  Yeah. So the next plug in to fill out the function.  Yeah. Yeah. So, uh, for one way Anova, I think the function in.  Or the sun. Will be.  Yeah. No idea. I think I can just show the just one.  So, uh, yeah, you can try out the, uh, the Google sheet, doing it in the calculation, but showing the, uh, just version.  So for this. Analogue machines require something like install and override.  Yeah, it's like a different pattern. Yeah. So for Jasp, we just copy the data.  So you have three, uh, three variables, three layout variables.  And then you open, you go to Edit data layout paste.  So now this is your, uh, data prepared for TV, a one way Anova with three variables list mix and uh, grid.  Then you click on uh edit data, then select Anova, then Anova for one way Anova uh and repeated measure and whatever.  So for now we'll just go with Anova over here.  Uh uh layout is the fixed factors.  And your task completion time is your.  So over here, you see, there is statistically, uh, significance, uh, f p value and f score and the same like d f.  So this suggests that there is a significant interaction, uh,  a significant effect of changing the layout between, uh, three groups on task completion time.  So when you change the layout, there is, uh uh, yeah, the task completion time will significantly be different and the performance will be different.  So once you run this, uh, now, you know, the overall effect that between least between grade or between,  uh, between mixed, there is some one condition which is statistically, uh, different.  Not necessarily all the conditions are different, but at least one group is different.  Yeah. So to know which which one uh, is okay.  So yeah, descriptive statistics is just your mean median and other, uh, standard deviation.  But if you want to know uh, further down. So let's say if you got the statistically significant results in one way Anova.  Now you want to see what is the interaction effect. Which condition perform the best.  So one way over here you can see the mean value of least uh time taken completion time was highest.  So list is anyways back. And there is a conflict between mixed and grade.  So you can say something, but you can't say statistically whether it's significant or not.  Just by looking at the mean.  You can derive like a pattern from here, but to, uh, further and further deep, uh, dig down, uh, in that you have to run post hoc test.  So for post hoc, so post hoc, once you have significant results, then you go to post hoc.  It's called uh, post hoc. And there are variety of test. And for every test there are different versions of post-hoc and post-hoc suggest that uh,  that which which interaction is better or which condition or group was better.  So layout we selected over here and then you select correction.  So this is not in the scope I not.  Yeah. Yeah. So yeah. So and then you select the confidence level %.  So if you see over here this is your uh post-hoc test.  And if you see over here your t value.  Uh, yeah. So over here this says that, uh, and this is higher grade and list are statistically significant.  The T value minus three, uh, ..  And then uh grade and mixed. Are not significant.  And then list and uh mixed are also statistically significant.  So you got like a comparison of all the conditions.  So once you are done with the uh, statistical Anova, one way Anova, then you run this post-hoc Anova and then you report, uh, this p value, uh, again.  Um, so. And for inter preventing the.  Unknowable. Yeah. So this is uh.  Yeah. So higher the f value the more like didn't click.  Yeah. So the higher the f value the more likely.  Uh, there are six statistically significant difference between the group means again % confidence interval is the commonly used in HCI studies.  And if F score is greater than the critical value the we reject the null hypothesis indicating significant differences between group means.  So to report it you just say like A way Anova.  So this is a standard template you can actually use.  There is no you don't need when you report the statistical results.  You don't need to be creative. You just use that sentence. So in SPSS software and everywhere you see like this standard template.  So yeah one way Anova test using task completion time as the independent as the dependent variable.  And the layout design as the independent variable suggests that there is a significant difference among the three conditions this,  this, and then after that you go and say that. Then further, a post hoc analysis was done using this.  And we found that grade versus um lists were statistically significant.  Same report the value. And then you say also grade versus uh mixed are also uh statistically significant.  So that's how we just report the the data. Yeah.  And so once you use that formula for the one way, uh, for one way Anova, then you have.  So this is like a f table for uh, for the so like how you have t test, uh, has t table.  This has F table. And it has four different uh versions.  So we have to search for if you want to do it by yourself and, you know, manually try the f value and all that.  Just search for f table .. So this will give just this table.  And similarly over here you have your degree of freedom.  So you just select which one. And then if the vet. So this would be a critical value.  And any value higher than that f value would be uh significant.  So now giving and any questions so far. Maybe you can see where the TV has come from.  Google. Oh, I mean, I don't know. Statisticians might have.  Yeah, they might have made it. Yeah. Do not confuse the thing you have to create.  No, you don't have to create the table. It's already there. Yeah.  I doubt after years of experiment. Yeah. Values. Yeah.  So this basically says, uh, see how much sample size you need to get the confidence value or whatever.  So when we design the experiment and you someone ask how many participants do you need.  So for that you have to check, uh, over here based on your degree of freedom.  Let's say if you start by thinking, okay,  participant, then your degree of freedom would be this.  Then your confidence. Or let's say if your confidence level is this, then what should be the degree of freedom?  If you want your t value, uh, p value or f value, I mean your t value to be higher.  Yeah. Okay. So next are some of my experiment examples.  So this is from, uh, my uh, PhD last year.  Uh, experiment. So where I designed a, uh, context aware empathic virtual reality system.  So where we, uh, change. I mean, for me, the independent variables for, uh, the emotion adaptive environment.  So where I was changing the colour of the environment based on the recognised emotional states.  So for, for example, happy for yellow for happy green for relax, new, uh, red for stress and blue for both.  So I was change. So that was one of the variable that I had.  And the second uh, variable that I had was around the empathic, uh, assistance of the agent.  How so? These were my two independent variables, and I used physiological signals to predict the emotional states.  And so, yeah, this was a methodology two by two within subject, uh, study with around  to  participants.  So I because it was a new interface and I didn't want to use a lot of participants, so I just went with,  uh, two by two within subject, two by two because I had two independent variables.  So when you say, uh, how to explain.  Okay. So there's no way to explain a x.  So okay, imagine a grid of two by two and you have one side.  Uh, you have independent. Independent. You can do that. Two. But on the whiteboard I have my handwriting is bad.  So independent variable. Uh, imagine. Yes. Independent variable.  Like how you create truth table or Boolean table. Right. Yes.  Emotionally adaptive environment and, uh, no emotion adaptive environment.  And so x axis and the y axis, uh empathic companion versus no empathic companion.  So one condition was. The country.  So you have one condition was when it's a baseline, when there is no empathic or empathic companion, no emotion, adaptive environment.  And then second condition when I. Oh, that.  That's better. Yeah. That is better. Yeah.  So, uh, one condition. Yeah. I should have added that slide also.  Uh, I can uh, just going to go what he's extending.  Yeah. Okay. Yeah. Yes.  Uh emotion adaptive. Yeah. No.  Emotion adaptive. Yeah. No one is uh, emotion empathic companion.  Easy companion. No. And no I think yeah, yeah.  So when we have two independent variables and we want to design a within subject study, this is how we can, uh, design it.  So you have one condition will have both when the environment is changing its colour and the agent is also, uh, empathic.  And then, uh, the, this condition like condition two, where, uh, only the agent is empathic, but then there is no change in the environment.  And then third is when the environment is changing and the, uh, empathic companion is not, uh, adaptive.  And condition four is when nothing is there, just the baseline.  So eventually I just want you to see which, uh, if by changing the environment colour based on the emotional state and when the agent is,  uh, empathic, whether it, uh, changes the emotional state.  So for that, I use the self assessment mannequin.  So if you look at my dependent variables. So for emotional state I use the self assessment mannequin Questionnaire.  Then for to understand the presence whether the person felt present in VR or not.  So for that I use the I group presence questionnaire then for uh cognitive load game experience questionnaire for positive effect negative effect.  So these were all my dependent variables that I wanted to measure.  If having these, uh, conditions impact these, uh, these variables or not, then when we, the person interact with the empathic companion,  uh, whether the person's flow state would be induced or not or better or not, and then whether the human would trust a agent or not.  So I use this, uh, subjective questionnaire. Then I use the physiological.  So I used EEG electrodermal activity and heart rate variability.  And then for the behaviour I use the task performance and error rate and rate of assistance.  So this is how when like when you design your experiment, this is how you can uh uh write about it and then design the within subject study.  So uh, for this I, I couldn't use one way Anova, so I had to use repeated measure.  But then before that I had to check whether the data is normally distributed or not.  So, uh, I gave only one example over here.  This is from my thesis. Uh, so only for the trust scale, uh, when the data was normal.  So I ran the Shapiro test to run the to check whether the data is parameter normally distributed or not.  If it's normally distributed, then I ran a two way repeated measure Anova because it's a two by two two independent variable and, uh, two conditions.  And then yeah, just uh, reported like, uh, Anova results showed a non-significant, uh, main effect of emotion adaptation.  Uh, but again, significant effect of context of empathic uh was observed like empathic interaction was observed.  So basically this result suggests that when the agent was present, uh, empathic agent was present,  that the participant perceived more trust towards the person, uh, towards the agent, like empathic agent.  So this is this is what I could drew from my, uh, experiment.  And then after that, I ran a post post hoc analysis, uh, estimated mean margin comparison.  So which reveal that the there was a significant difference between BDI and in contrast.  So yeah, basically I just reported individual differences as well.  And yeah. So this is how I just prepared the report.  Like f value, p value, add value p value. And then this is the bar plot of uh that.  So which says like there is a significant difference between B and D condition.  So I think B was the emotion adaptive.  And D was then the emotion adaptive. And the companion was there something like that.  So yeah this was the. Oh, yeah.  This was the experiment design. So I think I'm done with my session.  Anyone have any questions? Yes.  No. Can you really explain that to this table?  Uh, yeah. So, I mean, forget the name Alex, because that's another measure.  But this is the system scale report. So, uh,  to .  So  is the degree of freedom over here. And.  Yeah. So, uh, emotion adaptation for emotion adaptation variable the system to scale Anova result.  Uh, f score was . and p value was ..  So not significant p value should be less than ..  Then it will be significant. And for context aware empathic uh like empathic companion the F score was ., but the p value was ..  So that's why it was significant. Uh, significant, uh, different.  And the interaction effect. So uh, whether uh, the two independent variables have any interaction effect or not.  So that's like within subject if there is any error or something.  So uh, so for that interaction effect it. So when you run Anova it will also give the interaction effect p value as well.  So which is like . to f f value. And p value is ..  So there is no interact like interaction effect is not significant.  Uh yeah. This is what it is, just one way of representing.  So this is because I didn't want to write too much, just want you to show the data over there.  If you have limited space then you can just use table. You have to read the flow.  Did you did we mean sorry. Yeah.  We didn't load it immediately. Once we have the time to become, uh, sources that we would like to how to write or how to.  How do you do that too? So what you have written here, you have explained you.  So this is from my paper. This is from my paper.  But I think the reading material, your reading material have some information around Anova and t test.  But, uh, your experimental method, the book, uh, that they do not have the formula.  So it's very high level because it's in nature. You don't need to know like the formulas underneath.  Just have to have some idea what is Anova, what is changing in Anova and what is changing in t test, things like that.  So in your book, I think they didn't discuss too much about the p value and the Gaussian bell curve and all that from the material that you had,  I just added so that you can know more in some hands on on Google Sheet.  Yeah. So this is from my paper, uh, and my thesis.  Any other question? Yeah.  I mean, in the book you have they have explained t test, interpreting t test, then they have explained about Anova very short description of Anova.  But then they talked about one way Anova, factorial Anova, repeated measure Anova, then something called split Anova,  which is like multifactorial mixed design Anova and then assumption of Anova like assumptions that you have to keep.  So that's like the data should be normally distributed for t test.  All the participant size should be same. And your um yeah for Anova it doesn't matter.  It could be different. Like the participant size could be different.  Yeah. So these are the assumptions. So that's what in the book. Okay.  So if you don't have any other question, I think we are before time.  Seven minutes. More slides.  Uh, and no, I mean just yeah, I because it's a guest lecture and I want to improve myself because this is my one of the few lectures that I've taken.  So would value feedback from you. It's and it's all anonymized, so I won't know who failed.  What. So if you want to say bad things, it's also good. I mean, it's my way of learning.  Yeah. So. Yeah. And then this, if you are done with this is me and that's my LinkedIn.  Yeah. Thank you. Okay.  Yeah. Thank you so much, Kunal, for sharing this. You know, statistical test is never easy to lecture lecture on because it's a lot of us.  It's not our background. We sort of learn mean standard deviation in the pass, but not until this degree.  Um, however, things like T-test, Anova, they exist in all the research, not just HCI.  You look at medical papers, psychology papers, they use these tools.  And most often we have to pick up this when we start doing research.  And it becomes challenging because no one ever taught us we have to read the books. So I understand there's a lot to digest.  Take your time to slowly try to understand and ask questions afterwards.  You know, that's totally fine. I'm sure Cornell is open to any questions you have.  Any questions you want to clarify with him? Please do so.  Another very easy way too is during standups.  When you meet your tutors, you can talk with them, ask them, you know, maybe you have some issues plugging the value.  Exactly how how to find the different variables. What is DF?  There's a lot of things going on, isn't it? So try to understand these. What you learn today will be within the exam.  So it's important to understand this. But I'm not trying to kill you. Yeah so don't worry.  I'm not trying to kill you. For example, something like Anova went through the, uh, formula very quick.  It's more about answering the concept, but I will ask a little bit of calculation for the t test.  And if there's any material required like the table it will be provided.  Okay. So try to understand it a little bit. I will also tell you uh, sort of my own hack, but I just started on how I try to understand these things.  Yeah. And also like how HCI researchers approach this because as you saw, there's a table, there's a bell curve.  And all this usually practically when you do this research, you don't need to dig through all the numbers.  We use the tools, we use SPSS, you use Jasp, we use Excel.  So once you collected the numbers and the data from your participants you put into the software.  And we get that p value the significant significant value. And usually we just see is it above or below ..  If it's below . we are happy because there's a significance between the condition.  If it's above, generally we are unhappy because our conditions are not significant.  It means that, you know time taken between grade and lists.  We want to ensure that the difference, the time taken between grade and list, there is significance.  So we want the p value to be less than ..  That's generally our goal. There's a lot of ifs and there's a lot of exceptions.  But that's generally the goal. And today we look at T-test and Anova.  Do we. How I used to look at it at the start is that if there are there's more to it.  But in general if there are two conditions grid and lists, we look at t test if there's more than two conditions lists,  mix whatever and any other conditions that you came up with.  It tends to go towards Anova tests. Right. So so that's how we look at it.  And so we have grid and lists in this.  We have grit, grit and list. We have the average value.  Average value. So t test will let us know between these two grit and lists.  If it's like this one is higher average value. Is this difference significant.  So green lists. But if we have three conditions grit list mix becomes more complicated.  Right. So what Anova actually does when you put in these three conditions and it tells you that is significant.  First of all it'll tell you is it significant or not. But so let's say you get a value yes is less than ..  But between grit list mix. What how do you say you just say is significant.  It doesn't tell you much you need to know. Is it between these two? Is it between these two or is it between these two?  Is grit better than list is little bit and mixed. So this is what Anova tries to do.  The first thing they do is they tell you that a significant exists.  Then afterwards you run that thing called the post-hoc which then tells you is it here?  Is it here or is it here? So that's what post-hoc does.  Uh, this just a concept to understand because when you read research papers like the example Kunal show, you can get quite complicated.  Two independent variables comparing between different means.  So it's good to understand this concept, but the test itself will try to keep it as simple as possible.  Yeah, I'm not going to throw a very hard condition. And if there's any calculation, if one of you will lean more towards the t test,  like I know if I just try to understand the basic concept which was covered in the book,  and take your time to understand this, uh, material, there's still a few more weeks and discuss with your tutors as well as Cornell.  You can email to him as well me as well if you want to ask any more questions about how this works.  Okay. Yeah. Great. All right.
