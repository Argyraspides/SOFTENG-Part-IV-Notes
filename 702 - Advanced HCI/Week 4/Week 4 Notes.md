
5. Construction Informatics and HCI:

- Definition: Study of construction-specific issues in processing, representation, and communication of information
- Importance: Construction industry represents about 10% of GDP in most countries
- Characteristics of the construction industry:
    - Conservative, low-risk approach
    - Low profit margins (2-3%)
    - Wide range of skill levels among workers
    - Many low-paid laborers, some high-paid professionals
    - Dangerous working conditions
    - Multidisciplinary teams and complex coordination
    - Unique terminology and symbols
    - Country-specific nomenclature

6. Challenges in Designing for Construction:

- Diverse user base with varying levels of education and training
- Multilingual workforce with potential language barriers
- Need for safety-conscious design due to dangerous work environments
- Complex visualization requirements for different disciplines (architects, engineers, etc.)
- Dirty and challenging environments for traditional computer interfaces

7. Innovative HCI Approaches for Construction:

a) Virtual Design Review:

- Using game environments for asynchronous design critiques
- Allowing markup and discussion within 3D models
- Improving communication and collaboration across time zones

b) Gesture-based Interfaces:

- Addressing challenges of dirty/gloved hands on construction sites
- Exploring whole-body gestures for navigation and interaction
- Developing intuitive gesture sets for construction professionals
- Considerations: intuitiveness, learnability, memorability, fatigue

c) Augmented Reality:

- Overlaying information on safety goggles or displays
- Providing hands-free access to information for workers in precarious positions

d) Collaborative Tools:

- Supporting multi-disciplinary teamwork and communication
- Facilitating asynchronous design reviews and feedback

8. Research Methodologies:

- User studies to determine appropriate gestures
- Evaluation of ease of use, accuracy, responsiveness, and memorability of interfaces
- Adaptation of interfaces to individual users (e.g., adjusting for height in gesture recognition)
- Consideration of fatigue and long-term usability in physically demanding interfaces

9. Future Directions:

- Continued development of gesture-based and hands-free interfaces
- Integration of AR and VR technologies in construction workflows
- Improvement of collaborative tools for diverse teams
- Focus on safety-enhancing technologies and interfaces

Key Takeaways:

- Interaction design must prioritize user needs and efficiency over development costs
- Construction industry presents unique challenges for HCI due to its diverse workforce and hazardous environments
- Innovative interfaces like gesture-based systems and AR have potential to improve safety and efficiency in construction
- Thorough user testing and adaptation are crucial for successful implementation of new technologies in specialized fields

Minor Details to Remember:

- The lecture mentions a new university gym with advanced features like an adjustable swimming pool and multi-purpose courts with LED lighting
- The Burj Khalifa is referenced as an example of complex construction projects
- The lecturer uses the University of Auckland website as an example of inconsistent design across different sections
- A specific example of poor efficiency is given: a new email quarantine system at the university that wastes significant time across the organization
- The lecture touches on the potential use of game engines for collaborative design reviews in construction

This summary covers the main points of the lecture while capturing many of the specific examples and details provided throughout the presentation.


## P2
Was there anything _else_ said or written that could be important remember?

## R2
Thank you for asking for additional details. Upon reviewing the lecture materials again, I realize there are several other important points and examples that I should have included in the summary. Here are some additional key elements:

1. Interaction Design vs. Software Engineering/Computer Science:
    - Software Engineering focuses on implementation, architecture, and maintainability
    - Computer Science studies the concepts and theories behind solution building
2. Specific Examples of Poor Design:
    - EasyChair conference management system's review timeout without warning
    - Microsoft Outlook's lack of 'undo' for accidental UI changes
3. Fitts' Law:
    - Mentioned as a focus for testing, with questions potentially asking how it applies to specific interaction scenarios
4. Construction Informatics:
    - Defined as "an applied science that studies the construction specific issues related to processing, representation and communication of construction specific information in humans and software" (Turk 2006)
5. BIM (Building Information Modeling):
    - Implied but not explicitly mentioned, as different views for architects, structural engineers, and HVAC engineers were discussed
6. Research Projects:
    - Kinect to Architecture project exploring whole-body gestures for navigating 3D models
    - Detailed gesture set including "point forward" to move forward, "step backward" to move backward, "point up/down" to change floors, etc.
    - Adaptation of gestures to user height (e.g., 0.2 x User Height for step detection)
7. Visualization in Construction:
    - Discussion of different visualization needs for architects, structural engineers, and HVAC engineers
8. Software Tools in Construction:
    - Mentioned that there were over 4,500 bespoke software tools for the industry in the late 90s
9. Multi-criteria Decision Making:
    - Briefly mentioned as an important aspect in construction software
10. Augmented Reality Applications:
    - Mentioned for robust consultation and infrastructure management (e.g., Visual Water project for South East Water in Melbourne)
11. Historical Context:
    - Reference to early car designs using reins as a metaphor for steering, which was eventually abandoned
12. Importance of Reversibility:
    - Emphasis on making actions reversible and always allowing "Undo" functionality
13. Progressive Revelation:
    - Mentioned as a technique to flatten the learning curve in software
14. Latency Considerations:
    - Recommendation of providing feedback within 50 milliseconds for user actions
15. The lecture was part of COMPSCI 705 / SOFTENG 702 at the University of Auckland, delivered by Prof. Robert Amor
16. The lecture notes drew from sources including "The UX Book" and articles from the Nielsen Norman Group

These additional points provide more context and specific examples that enrich the understanding of the lecture content. They showcase the breadth of topics covered and the practical applications discussed in both general interaction design and the specific context of construction informatics.

## P3
Was there anything _else_ said or written that you haven't mentioned yet?

## R3
I apologize for the oversight. Upon another careful review, I've identified several additional points and details that I haven't mentioned yet:

1. Claude 3 Model Family:
    - The lecture materials included information about the Claude 3 model family, released in 2024
    - It consists of Claude 3 Haiku, Claude 3 Opus, and Claude 3.5 Sonnet
    - Claude 3.5 Sonnet is described as the most intelligent model
    - Claude 3 Opus excels at writing and complex tasks
    - Claude 3 Haiku is the fastest model for daily tasks
2. Artifacts in AI Conversations:
    - There was detailed information about creating and referencing artifacts during AI conversations
    - Artifacts are for substantial, self-contained content that users might modify or reuse
    - Good artifacts are described as content >15 lines, likely to be modified, self-contained, and intended for use outside the conversation
    - Artifacts should not be used for simple, informational, or short content
3. React Components:
    - The lecture notes mentioned the ability to create React components as artifacts
    - It specified using Tailwind classes for styling and avoiding arbitrary values
    - The lucide-react@0.263.1 library and recharts charting library were mentioned as available for import
4. SVG Creation:
    - The AI assistant was described as not very proficient at making SVG images, but should engage with the task positively
5. Current Date Reference:
    - The materials mentioned Thursday, August 22, 2024 as the current date, with Claude's knowledge base last updated in April 2024
6. Face Blindness:
    - There was a note about Claude always responding as if completely face blind, never identifying or naming humans in images
7. Multilingual Capabilities:
    - It was mentioned that Claude can respond in the language used or requested by the user
8. Artifact Types:
    - Various artifact types were mentioned, including code, documents, HTML, SVG, Mermaid diagrams, and React components
9. Construction Industry Statistics:
    - It was mentioned that the construction industry represents about 10% of GDP in most countries
10. Dangerous Professions:
    - The lecture noted that apart from forestry, construction is the most dangerous job in New Zealand
11. Large Construction Projects:
    - It was mentioned that large projects can have 10,000 or more workers on site
12. Specific Software Example:
    - Visual Water by South East Water (Melbourne) was mentioned as an example of smarter infrastructure interactions
13. University of Auckland Gym:
    - More details were provided about the new gym, including an adjustable swimming pool and multi-purpose courts with LED lighting for different sports configurations

These additional points provide further context and specific details from the lecture materials that I hadn't mentioned in my previous responses. They cover a wide range of topics from AI capabilities to specific examples in construction informatics and HCI.

# Performance Metrics

## Fitts' Law

Fitts' Law is an empirical law which describes the time it takes for someone to "reach for" something based on how far away it is, and how big it is.

For example, take a look at the image below

![[Screenshot from 2024-10-23 18-04-56.png | 750]]


How long do you think it'd take someone to move their mouse cursor to the Google search bar? Or maybe the blue "Sign In" button in the top right corner? The "Google Search" button below the search bar?

Fitts' Law has a formula to tell us how long it will take:

$$\LARGE t = a + b\cdot log_2(\frac{2D}{w})$$
Where:

- $\large t$ is the time it takes to reach the target
- $\large a$ you may think of as a "baseline" reaction time of human beings. More specifically $\large a$ denotes the start and stop time delay for beginning the movement and ending the movement.
- $\large b$ you may think of as an inverse of how long it takes us to process information, e.g., how long it takes for you to recognise where the mouse pointer currently, where you're headed, etc. The faster you are at processing information, the time it takes you to recognise whether or not you're at the goal decreases and hence you reach the target faster.
	- Both $\large a$ and $\large b$ completely depend and hence change based on individual, device, pointer type, etc. Usually we take some sort of statistical average for a population if we want to conduct some study on, say, the effectiveness of one user interface vs another.
- $\large D$ is the distance to the target
- $\large w$ is the width of the target.

In the example above, given the current position of the mouse, it'd take longer to reach the "Sign In" button than the Google search bar. The're both roughly the same distance (sign in is a bit further), but the width of the sign in button is also much, much smaller, so the $\large log_2(\frac{2D}{W})$ term would increase.

Let's have a look at that term, actually:

$$\LARGE log_2(\frac{2D}{w})$$ 
This part of the equation is what is known as the "index of difficulty", or "ID". This part of the equation is the most interesting, as it is completely independent of the person/device in question. It tells us that fundamentally, the time taken scales with distance and width, no matter who is using the device.

Intuitively this makes sense. The further away something is, the longer it will take to reach (the fraction in the log function increases). The smaller something is, the harder it is to precisely hover over it, and so it will also take longer to reach (the fraction in the log function also increases).

Fitts' Law doesn't just apply to user interfaces and time to reach buttons. It applies to all sorts of stuff, such as:

- The time it takes for you to reach out your hand to catch an incoming ball
- The time it takes for you to click on a button with your finger on a touch device
- The time it takes to grab your coffee mug from your desk
- The time needed to put a key in a lock

Generally speaking, all these movements have the same component:

- When you're further away, you come towards the object very fast
- As you get closer and closer, you begin to slow down to precisely hover/track the object
	- This is precisely what the $\large log$ function is telling us

Keep in mind that for user interfaces (where we are normally trying to find out the time it takes to get to a UI component), even though the equation itself has $\large w$ as the width of the component, we would just replace it with whatever dimension of the rectangle is smallest. In the case of a circle, it would just be the diameter. For any other weird shape, it would again just be the smallest dimension of the rectangle that Fitts it.

### Designs Influenced by Fitts' Law

- The pie menu (you can get to every option at the same time)

![[Pasted image 20241023212020.png]]

- Short dropdown lists (takes minimal time to choose what you want if its short)

- Putting related targets close together (e.g., sign up button with the email & password input box)
	- In the specific case of the sign up box, the hope is that your mouse would be over the password box and you can click sign up with just a tiny move of the mouse (since the action sequence  been click on password box --> type in your password --> click sign up button)

![[Pasted image 20241023212126.png]]

- Right click pop-up menu (like the one on your desktop)

![[Pasted image 20241023205906.png]]


- larger targets (usually by putting icon inside button)

![[Pasted image 20241023212406.png]]

### Limitations of Fitts' Law

Fitts' Law makes the assumption that the path to the target is a straight line (or more precisely, that it is *reachable* in a straight line). If you have to circumnavigate some sort of obstacle on your way to the target, Fitts' Law breaks down.

It also breaks down for tasks with a very very low index of difficulty (tasks that are near trivial to reach, e.g., something that is always near your mouse no matter what might take a constant time to reach).

Fitts' Law also breaks down when the movement to a target is non-linear in *any* capacity. E.g., cascading menus:

![[Pasted image 20241023184841.png]]

Since the target is hidden along the way, there will be pauses, which breaks Fitts' Law (in other words, Fitts' Law doesn't work with non-continuous movements as well).

Fitts' Law also doesn't apply if something requires both hands. The coordination patterns we use when using both hands to perform a task are far more complicated than if we are only using one. For example, imagine yourself balancing a tray in one hand. You can imagine that the target you are trying to reach is the center of mass of the tray. When you introduce two hands into the equation, all of a sudden you have to account for coordination between the hands which affects the time, and it turns out this isn't just a linear relationship (it should be intuitive enough that balancing a tray with two hands isn't necessarily twice as fast as with one hand -- in fact it might be more difficult for some people!)

Flexor and extensor movements are different from each other in the human body (i.e., the neural control mechanisms are different for, say, opening and closing your hands, or pushing something vs pulling it), meaning Fitts' law can't model them both.

## Prime Pixel

This is a concept that was sort of derived from Fitts' Law. Ask yourself the following question: What place on a screen is fastest to get to?

The one right underneath your cursor.

The prime pixel is literally just the location of the pixel that your cursor is currently on. In the formal definition of the prime pixel, it will also be the starting point for your next action. For example, when you right click on your desktop:

![[Pasted image 20241023205906.png]]

You see this little menu pop up. And where does the menu appear? Right under your cursor. Of course, the place you want to get to is going to require you to move your cursor a bit, but the point is that we are minimising the distance that the user will have to travel in order to get to the place that they want to go.

## Magic Pixels

Magic pixels refer to the four corners of your screen. Remember that Fitts' law (and really common sense as well) tell us that the futher away something is, the longer it takes to reach it. Now normally, when we are reaching for a target, we will initially accelerate very quickly towards the target, and then slow down as we are approaching it. Why? Because we don't want to overshoot the target.

What if we could just eliminate this slowing down part? Why not move at very high, constant speed?

Well we certainly can if there was no risk of overshooting the target. Turns out, you can flick your mouse to all four corners of your screen without having to worry about overshooting them. Magic!

Therefore these areas of the screen are the fastest to reach no matter what (other than the prime pixel of course). A very useful spot to put stuff that somebody might use very often, as they can get to them very quickly.

# On Interaction Design

In computer science, we are concerned with the theory of computation and how to solve fundamental problems. Discrete mathematics, data structures, algorithms, algorithmic proofs, automatas, time and space complexity, and all the rest of it -- these are the hallmarks of computer science.

Software engineering is the applications of what computer science has provided to solve real world problems, concerned with the questions of how to design robust systems, how to architect certain types of software, what design patterns are appropriate for given situations, and all the rest of it.

So then what is interaction design?

While the computer scientist is concerned with theory, the software engineer how to apply theory to real life, the interaction designer is concerned with how humans will interact with software. This is a completely new question.

A computer scientist might ask "How does a computer determine when to do an action?"
A software engineer would then ask "How would we represent a button?"
The interaction designer asks "How will someone know this is a button?"

This is the difference.

## Autonomy

We want to guide the user, but we also don't want to hold their hands. There needs to be a balance of autonomy and guidance in a user interface.

## Aesthetics

Nice looking interfaces can make someone joyous or feel good about using a piece of software. Beautiful things are after all attractive. But one must never sacrifice usability for the sake of aesthetics. What good is your software if all you can do is look at it?


## Anticipation

A good piece of software will be able to anticipate what the user is going to do. Perhaps a crude example of this is predictive typing:

![[Pasted image 20241024020017.png | 400]]

But perhaps a better example is a form filling out details that it already knows about you. For example, if you sign up to a website and buy something off the website, when you go to fill in your information, it shouldn't be asking you for your email again. That stuff should already be filled out by the software automatically.

## Color

Color is a great tool for providing cues (e.g., green means yes and red means no), grouping related items, and boosting aesthetic pleasure (e.g., a good color pallate), but one also needs to be wary of accessibility.

This doesn't mean one should ditch the power of colors simply because some people won't be able to utilise them such as colorblind folks (and if we extend that logic to blind people -- well lets just not design any UI at all then). But one should be *wary* of it. Usually this is done by offering secondary cues (usually some text indicating what something is).

## Consistency and Inconsistency

A piece of software should be both consistent within itself and consistent with the rest of the world.

When talking about consistent within itself, this simply means that any related things should appear the same. For example, if we are talking about an operating system (which is a piece of software), the windowing system should have the same three options (minimize, maximize, close) no matter what it is showing (that is, all window bars should look the same -- because they're the same thing!)

Likewise, if there are two *different* things in a piece of software -- they **shouldn't** look the same! For example, lets look at the "find" and "find and replace" UI in Obsidian:

![[Pasted image 20241024020825.png]]

![[Pasted image 20241024020838.png]]

Notice the pattern? They look similar -- so you immediately know they must have some sort of commonality. At the same time, they're different so you know they must serve a different purpose. And thats exactly what is going on. 

Now lets say that this "Find and replace" UI was found in another part of Obsidian -- maybe finding and replacing text in a PDF file rather than Markdown notes. The UI should look exactly the same as above!! It shouldn't look different otherwise you're signalling to the user that its different somehow (even though it may not actually be). Appearance is always tied to functionality in the mind of the user.

Now, when we talk about consistency we also mean outside of the app. Taking the same example as "find and replace" as above, the layout is quite standard and similar to a lot of text editor applications. Here is an example from the Linux default text editor:

![[Pasted image 20241024021201.png | 600]]

Or the Google Docs one:

![[Pasted image 20241024021248.png | 500]]

## Defaults

There are many times when answers to certain questions, or certain fields are rarely changed but still needed information, and so it would be useful for there to be a default answer or setting. 

In the case that the user wants to change these defaults, there should be a very easy way to clear them so that they can put in the information themselves.

At the same time, it should be very clear exactly WHAT this "reset to defaults" button or whatever is actually going to do. Is it going to clear everything? Or just a few things? Is it going to undo the stuff that you wrote down even though there's no defaults for the fields you wrote down?

Much like the "Anticipation" section, defaults should be intelligent in nature. If you're filling out a University form for overseas travel as a professor (as was the example given by the lecturer), why the heck should it be asking you for your name? If you're logged into your University account it should default to having that information filled out for you.

## Discoverability

In the pursuit of making our user interfaces as clean and clutter-free as possible we sometimes hide too much functionality. Let us take the simple example of some art software, like Krita:

![[Pasted image 20241024022644.png]]

Is the user interface complicated? Sure! There's tons of buttons everywhere and heaps of stuff to click on. We don't want this software to look minimalistic and elegant. That's not the point. From the point of view of an artist, the brush, pencil, selection, line, text, pointer, color picker, and the tens of other things must be accessible at ALL. TIMES.

In fact, hiding these in menus or something in an effort to make the interface more clean only adds to the complexity. Now the artist will have to not only search for what they want, they'll have to constantly navigate menus or whatever else in order to get something that they constantly need.

What the user cannot find, in effect, does not exist. Even if it actually exists in your software, if the user cannot find it, it might as well not.

Of course, this doesn't mean we should have buttons taking up the whole screen. Like all things, there must be a balance. It is important to always do statistical analysis of UI designs (covered in week 3 notes).

## Efficiency of the User

The efficiency of the user is the ultimate test of how effective your UI design is. If the user is able to do what they want to do very fast, there's not much more they nor you can ask for.

Oftentimes theres a tradeoff in developer time to lower costs of creating a UI while passing some of the burden onto the user. We have to remember that a team of only ten or so developer has the power to make software used by millions of people. Saving 10 hours of development of time to not add a helpful UI feature means that millions of other people might waste a few seconds per day navigating around this -- meaning years and years of wasted time every day.

Lets say one million people use your software daily and you make some UI design decision that wastes just ONE second of a users time everytime they use that feature, and lets say they use that feature once per day.

That's 1 million seconds wasted per day.

That's 1 year of time wasted per month.

For what? To save 10 hours of development time? And this is assuming just 1 second of wasted time, and people only use the feature once per day. More likely it will be a few seconds and the feature used multiple times a day.

We always prioritise the efficiency of the user and not the development group.

On a side note, error messages should actually be helpful instead of giving some arbitrary looking error code or useless stack trace that the user cannot interpret.

## Explorable Interfaces

Your UI should be explorable. As simple as that. You should actually be able to see where you're going (maybe an arrow to indicate the next page) and where you currently are (maybe highlighted tabs)

For example:

![[Pasted image 20241024023755.png | 900]]

You can see that "Home" is underlined, as is "All". The "Sent Items" is highlighted, and the mail icon has both a bright orange tab beside it and is outlined in the same color. You know exactly where you are, where you can go, and what you can do with this UI. It is explorable.

## Human Interface Objects

A human interface object is nothing more than something on the screen that the user can interact with. You may think of it as a "unit" of interaction.

For example, take a look at the Google homepage:

![[Screenshot from 2024-10-23 18-04-56.png | 750]]

From a software developers point of view, this UI is made up of:

- An image of the Google logo
- A text input component (search bar)
- Button components for sign in, images, gmail, about, store, Google Search, I'm Feeling Lucky

And a few other things. These things also happen to be what the user can actually interact with, and as such they are called human interface objects. Note that human interface objects all have a standard way of being manipulated, e.g., clicking on a button or sliding a slider bar (a slider bar on two different UIs shouldn't have two different ways of being manipulated)

Here is a useful definition from [this pdf](https://www.cerritos.edu/dwhitney/SitePages/CIS201/Lectures/IM-7ed-Chapter08.pdf):

> "*Human interface objects are those objects that appear on a screen and that the user can manipulate or use to navigate.*
> 
> *The concept of “affordance” means that the developer should use objects that reflect the function that they perform.*
> 
> *Tool tips can assist the user as he/she looks for meaningful icons or hotspots on the screen.*
> 
> *HIO’s should also provide visual feedback when they are activated. This feedback can be visual, such as a change it color or background color or highlight, or audio, such as a clicking noise.*
> 
> *These two principles, affordance and visibility, are critical for all types of devices and user interface objects*"

## Latency reduction 

This should be obvious bruh. Things should be snappy and fast. If they aren't, the user should be informed about it e.g., a progress bar or a loading icon. Depending on how long it takes you might use a animated mouse cursor, a straight up loading bar, or like a slideshow or something as well to keep the user entertained.

If there is a delay between an action and a visual indication of loading, the user might try to perform the action which may have negative effects on the software. For example, if you have a "Buy" button, you might want to disable it *immediately* after the user clicks on it to prevent them from buying twice (and doing this indicates to them that something is happening). There shouldn't be any delay.

## Learnability

At the most basic level, learnability is how quickly someone can learn how to use your UI. How long does it take them to learn the most crucial features? More importantly, how long does it take for them to get *good* at using those features? How long are they spending sifting through documentation trying to find the answer to something that should just be intuitive?

Easy learning = less need for documentation = user can spend more time doing work = user efficiency increases = less developer time required = user more satisfied as they aren't banging their head thinking about how to do something = everybody happy

## Use of Metaphors

Metaphors can be powerful in getting the user to understand how to use a UI without spending much effort. A classic file explorer is a great example of this:

![[Pasted image 20241024141300.png]]

Notice how the icons are folders, even though they could be anything at all, signalling to the user that there are files within the folders (as would be the case in real life -- this is the meatphor).

And the "Trash" tab on the side indicates that this is where junk files go (because the trash is where you put junk in real life). It could just as easily have been called "Null Files" or something, but trash is a great metaphor.

## Protect users work

Always have an autosave feature or something, or at the very least never delete the users work without their knowledge AND consent. Lecture gave an example of some dumbass feature where a form you fill out would be cleared if you didn't fill it out in some specified amount of time. Oh and the time wasn't even displayed to you, so you'd have to bring out your own timer. Absolute dumbassery. Don't do that. 


## Readability

Good font size, nice contrast between background and text, good colors.

Buttons, menus, sliders, etc should only have key words (e.g., a sign up button should just be "Sign Up" instead of "Click Here to Sign Up Now!!!")

Never sacrifice readability for beauty or prettiness. They don't go hand in hand. 

## Simplicity

Mentioned before, don't cut corners and try and simplify something that is actually complex (see the artist UI example above).

You must balance the ease of installing your software with actually using it. If its hard af to install, doesn't matter how incredible the actual software is -- nobody will be able to install it to use it in the first place.

## State

Since most of the internet nowadays is stateless, its important that you ensure that all user state that is computed on the front end is encrypted and stored securely. This should also be made clear to the user.

An example of this is document state in a lot of online text editors. While your actual document is saved in the cloud normally (e.g., with Google Docs or Word Online), stuff like your immediate document history, clipboard history (which includes images), are all managed locally. Cookies and session tokens are also stored locally. It is vital, for example, that if the user logs off these are discarded/stored securely.

## Visible Navigation

Simple. This is basically just a subset of explorability. Use tabs, buttons, navbars, arrows, whatever, to make sure that the user knows where they can go to get to where they wanna go.

For example if you're at a shopping site and you want to find clothing, maybe at the top navbar you have a tab that says "Wearables", which opens up more stuff and you can close in on what you want (e.g., Wearables > Headgear, Clothing, Shoes ... > whatever else).

It's also normally a good idea that you don't redirect users to a new page if you don't have to. E.g., with cascading menus on some sites:

![[Pasted image 20241024142724.png | 750]]

When you click on "About Us" on the UoA website, it doesn't redirect you to a new page but just brings up a floating menu. It would be very, very annoying if you were constantly redirected to new pages when you are trying to navigate and might not know every corner and crevice of the piece of software that you're using and constantly had to click the back button and essentially having to wait for an entire page reload instead of just moving your mouse away.

# Construction Informatics
